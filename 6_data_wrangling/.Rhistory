# Combine words and sentiments w/ inner_join(), which only keeps words associated w/ a sentiment
tweet_words %>% inner_join(nrc, by = "word") %>%
select(source, word, sentiment) %>% sample_n(10)
# Combine words and sentiments w/ inner_join(), which only keeps words associated w/ a sentiment
tweet_words %>% inner_join(nrc, by = "word") %>%
select(source, word, sentiment) %>% sample_n(10)
# Combine words and sentiments w/ inner_join(), which only keeps words associated w/ a sentiment
tweet_words %>% inner_join(nrc, by = "word") %>%
select(source, word, sentiment) %>% sample_n(10)
# Combine words and sentiments w/ inner_join(), which only keeps words associated w/ a sentiment
tweet_words %>% inner_join(nrc, by = "word") %>%
select(source, word, sentiment) %>% sample_n(10)
# Combine words and sentiments w/ inner_join(), which only keeps words associated w/ a sentiment
tweet_words %>% inner_join(nrc, by = "word") %>%
select(source, word, sentiment) %>% sample_n(10)
sentiment_counts = tweet_words %>%
left_join(nrc, by = "word") %>%
count(source, sentiment) %>%
spread(source, n) %>%
mutate(sentiment = replace_na(sentiment, replace = "none"))
sentiment_counts
tweet_words %>% group_by(source) %>% summarize(n = n())
library(broom)
# So it would be best to compute the odds of sentiments appearing on each device
# We do this by calc the proportion of words w/ sentiment vs. proportion of words w/o
# then compute odds ratio to compare the devices
sentiment_counts %>%
mutate(Android = Android / (sum(Android) - Android),
iPhone = iPhone / (sum(iPhone) - iPhone),
or = Android / iPhone) %>% # or = Odds Ratio
arrange(desc(or))
se = sqrt(1 / Android + 1 / (sum(Android) - Android) + 1 / iPhone + 1 / (sum(iPhone) - iPhone)),
conf.low = log_or - qnorm(0.975) * se,
conf.high = log_or + qnorm(0.975) * se) %>%
arrange(desc(log_or))
# Testing our results: How does this tbl compare to randomly assigning sentiments to words? Could it be a fluke?
# We need confidence intervals
log_or = sentiment_counts %>%
mutate(log_or = log((Android / (sum(Android) - Android)) / (iPhone / (sum(iPhone) - iPhone))),
se = sqrt(1 / Android + 1 / (sum(Android) - Android) + 1 / iPhone + 1 / (sum(iPhone) - iPhone)),
conf.low = log_or - qnorm(0.975) * se,
conf.high = log_or + qnorm(0.975) * se) %>%
arrange(desc(log_or))
log_or
# Graphical viz of above
log_or %>%
mutate(sentiment = reorder(sentiment, log_or),) %>%
ggplot(aes(x = sentiment, ymin = conf.low, ymax = conf.high)) +
geom_errorbar() +
geom_point(aes(sentiment, log_or)) +
ylab("Log odds ratio for association between Android and sentiment") +
coord_flip()
# Which words are causing the above conclusion?
android_iphone_or %>% inner_join(nrc) %>%
filter(sentiment == "disgust" & Android + iPhone > 10) %>%
arrange(desc(or))
# Graphical viz of above
android_iphone_or %>% inner_join(nrc, by = "word") %>%
mutate(sentiment = factor(sentiment, levels = log_or$sentiment)) %>%
mutate(log_or = log(or)) %>%
filter(Android + iPhone > 10 & abs(log_or) > 1) %>%
mutate(word = reorder(word, log_or)) %>%
ggplot(aes(word, log_or, fill = log_or < 0)) +
facet_wrap(~sentiment, scales = "free_x", nrow = 2) +
geom_bar(stat = "identity", show.legend = FALSE) +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
update.packages()
library(dslabs)
library(lubridate)
options(digits = 3)
data("brexit_polls")
brexit_polls %>% head
brexit_polls %>% filter(month(startdate) == 4) %>%
str
brexit_polls %>% filter(month(startdate) == 4) %>%
nrow()
# How many polls ended on the week of 2016-06-12
brexit_polls %>% filter(round_date(enddate, unit = "week") == 2016-06-12) %>%
nrow()
?round_date
# How many polls ended on the week of 2016-06-12
brexit_polls %>% filter(round_date(enddate, unit = "week") <= 2016-06-12) %>%
nrow()
round_date(brexit_polls$enddate, unit = "week")
# How many polls ended on the week of 2016-06-12
brexit_polls %>% filter(round_date(enddate, unit = "week") == "2016-06-12") %>%
nrow()
# Which weekday did most polls end on?
brexit_polls %>% summarize(count = count(weekdays(enddate)))
# Which weekday did most polls end on?
brexit_polls %>% summarize(count = weekdays(enddate))
# Which weekday did most polls end on?
brexit_polls %>% group_by(weekdays(enddate)) %>% sum
# Which weekday did most polls end on?
brexit_polls %>% group_by(weekdays(enddate)) %>% summarize(count = count())
# Which weekday did most polls end on?
brexit_polls %>% group_by(weekdays(enddate)) %>% summarize(count = count(weekdays(enddate)))
# Which weekday did most polls end on?
brexit_polls %>% group_by(weekdays(enddate)) %>%
sum(weekdays(enddate))
# Which weekday did most polls end on?
brexit_polls %>% group_by(weekdays(enddate)) %>%
sum(weekdays())
# Which weekday did most polls end on?
brexit_polls %>% group_by(weekdays(enddate))
# Which weekday did most polls end on?
brexit_polls %>% group_by(count(weekdays(enddate)))
# Which weekday did most polls end on?
brexit_polls %>% group_by(sum(weekdays(enddate)))
weekdays(brexit_polls$enddate)
# Which weekday did most polls end on?
brexit_polls %>% weekdays(enddate)
sum(weekdays(brexit_polls$enddate))
weekdays(brexit_polls$enddate)
# Which weekday did most polls end on?
brexit_polls %>% summarize(weekdays = weekdays(enddate))
# Which weekday did most polls end on?
brexit_polls %>% summarize(weekdays = max(weekdays(enddate)))
table(weekdays(brexit_polls$enddate))
# Which weekday did most polls end on?
table(weekdays(brexit_polls$enddate)).max()
# Which weekday did most polls end on?
max(table(weekdays(brexit_polls$enddate)))
data("movielens")
head(movielens)
# Convert timestamp col into dates
as_datetime(movielens$timestamp)
# Convert timestamp col into dates
table(year(as_datetime(movielens$timestamp)))
# Convert timestamp col into dates
max(table(year(as_datetime(movielens$timestamp))))
table(year(as_datetime(movielens$timestamp)))[2000]
table(year(as_datetime(movielens$timestamp)))[13869]
# The year 2000 had the most movie reviews
(table(hour(as_datetime(movielens$timestamp))))
# The year 2000 had the most movie reviews
max(table(hour(as_datetime(movielens$timestamp))))
install.packages("gutenbergr")
library(gutenbergr)
library(tidyverse)
library(tidytext)
gutenberg_metadata
gutenberg
# How many diff IDs returned when searching for Pride and Prejudice?
gutenberg_metadata %>% str_detect(title, "Pride and Prejudice")
# How many diff IDs returned when searching for Pride and Prejudice?
gutenberg_metadata %>% filter(str_detect(title, "Pride and Prejudice"))
# How many diff IDs returned when searching for Pride and Prejudice?
gutenberg_metadata %>% filter(str_detect(title, "Pride and Prejudice")) %>%
distinct()
# How many diff IDs returned when searching for Pride and Prejudice?
gutenberg_metadata %>% filter(str_detect(title, "Pride and Prejudice")) %>%
distinct() %>% nrow()
?gutenberg_works
# Find the correct ID for P & P by filtering for the english version
gutenberg_works(title == "Pride and Prejudice")
# Download P & P
gutenberg_download(1342)
# How many words in P & P?
words = gutenberg_download(1342) %>% unnest_tokens(text, word)
# How many words in P & P?
words = gutenberg_download(1342) %>% unnest_tokens(word, text)
nrow(words)
# Filter stop words; How many words left?
words %>% filter(!word %in% stop_words$word) %>% nrow()
# Filter stop words; How many words left?
words = words %>% filter(!word %in% stop_words$word) %>% nrow()
# How many words in P & P?
words = gutenberg_download(1342) %>% unnest_tokens(word, text)
# Filter stop words; How many words left?
words = words %>% filter(!word %in% stop_words$word)
nrow(words)
# 37,246 words left
str(words)
# Remove digits from words; How many left?
words %>% mutate(word = str_replace_all(word, "\\d+", "")) %>% head
# Remove digits from words; How many left?
words %>% mutate(word = str_replace_all(word, "\\d+", "")) %>% nrow()
# Remove digits from words; How many left?
words %>% mutate(word = str_replace_all(word, "\\d+", "")) %>% filter(!"" %in% word)
# Remove digits from words; How many left?
words %>% mutate(word = str_replace_all(word, "\\d+", "")) %>% filter("" %in% word)
# Remove digits from words; How many left?
words %>% mutate(word = str_replace_all(word, "\\d+", "")) %>% filter(word != "")
# Remove digits from words; How many left?
words %>% filter(!word %in% stop_words$word &
!str_detect(word, "\\d+"))
# Remove digits from words; How many left?
words = words %>% filter(!word %in% stop_words$word &
!str_detect(word, "\\d+"))
nrow(words)
# How many words appear more than 100 times?
words
# How many words appear more than 100 times?
words %>% group_by(word) %>% mutate(count = count(word)) %>%
summarize(count)
# How many words appear more than 100 times?
words %>% group_by(word) %>% mutate(count = count(word))
# How many words appear more than 100 times?
words %>% group_by(word) %>% filter(word > 100)
# How many words appear more than 100 times?
words %>% count(word) %>% filter(word > 100)
# How many words appear more than 100 times?
words %>% count(word) %>% filter(word > 100) %>% arrange(n)
# How many words appear more than 100 times?
words %>% count(word) %>% filter(word > 100) %>% arrange(desc(n))
# How many words appear more than 100 times?
words %>% count(word) %>% filter(word >= 100) %>% arrange(desc(n))
# How many words appear more than 100 times?
words %>% count(word) %>% filter(n > 100) %>% arrange(n)
# How many words appear more than 100 times?
words %>% count(word) %>% filter(n > 100) %>% arrange(desc(n))
afinn = get_sentiments("afinn")
afinn
words %>% inner_join(afinn, by = "word")
afinn_sentiments = words %>% inner_join(afinn, by = "word")
# Proportion of positive affin vals
afinn_sentiments %>% filter(value > 0) %>% nrow()
# Proportion of positive affin vals
positive_vals = afinn_sentiments %>% filter(value > 0) %>% nrow()
afinn_sentiments %>% positive_vals / nrow()
positive_vals
positive_vals / 6065
# How many elements in afinn_sentiments have a value of 4?
afinn_sentiments %>% filter(value == 4) %>% nrow()
source('~/.active-rstudio-document', echo=TRUE)
fn <- system.file("extdata", "RD-Mortality-Report_2015-18-180531.pdf", package="dslabs")
system2("open", args = fn)
# Create tidy dataset from above pdf
txt = pdf_text(fn)
class(txt)
txt
library(stringr)
txt[[9]]
str_split(txt[[9]], "\n", simplify = TRUE)
x = str_split(txt[[9]], "\n", simplify = TRUE)
x
x = str_trim(str_split(txt[[9]], "\n", simplify = TRUE))
x
class(x)
str(x)
s = x[1]
s
length(s)
s = x[[1]]
length(s)
s
x = str_trim(str_split(txt[[9]], "\n", simplify = TRUE))
x = str_split(txt[[9]], "\n", simplify = TRUE)
s = x[1]
s
str(s)
x = str_split(txt[[9]], "\n")
s = x[1]
str(s)
s = x[[1]]
str(s)
# Trim s
s = str_trim(s)
s
# Find row w/ header
str_which(s, "^2015")
# Find row w/ header
str_which(s, "2015")
# Find row w/ header
str_which(s, "2015")[1]
# Find row w/ header
header_index = str_which(s, "2015")[1]
# Extract month from header
header = s[header_index]
header
str_split(header, "\\s+")
str_split(header, "\\s+")[1]
str_split(header, "\\s+")[,1]
str_split(header, "\\s+")[1,]
str_split(header, "\\s+")[1]
# Extract month from header
header = s[[header_index]]
str_split(header, "\\s+")[1]
header = str_split(header, "\\s+")
header[0]
# Extract month from header
header = s[header_index]
header = str_split(header, "\\s")
header
header[1]
header[[1]]
class(header)
class(header)[[1]][1]
header[[1]][1]
# Extract month from header
header = s[header_index]
header = str_split(header, "\\s+")
header[[1]][1]
month = header[[1]][1]
header = header[[1]][-1]
header
# Extract month and col names from header
header = s[header_index]
header = str_split(header, "\\s+", simplify = TRUE)
header
header[1][1]
header[,1]
header[1]
header[1,]
month = header[,1]
header = header[,-1]
header
# Find the "Total" row in s, find its index
tail_index = str_which(s, "Total")
tail_index
# Find rows w/ only one entry
str_count(s, "^\\d+")
# Find rows w/ only one entry
str_count(s, "\\d+")
# Find rows w/ only one entry
str_count(s, "\\d+")[0]
# Find rows w/ only one entry
str_count(s, "\\d+")[1]
# Find rows w/ only one entry
str_count(s, "\\d+") %>% filter(1)
# Find rows w/ only one entry
str_count(s, "\\d+") %>% filter(s == 1)
# Find rows w/ only one entry
str_count(s, "\\d+")
# Find rows w/ only one entry
class(str_count(s, "\\d+"))
# Find rows w/ only one entry
sum(str_count(s, "\\d+"))
# Find rows w/ only one entry
str_count(s, "\\d+") == 1
# Find rows w/ only one entry
sum(str_count(s, "\\d+") == 1)
header_index
# Remove all identified problematic entries
data = s[header_index+1:tail_index-1]
data
# Remove all identified problematic entries
data = s[header_index+1:tail_index-1] %>% filter(str_count(s, "\\d+") != 1)
# Remove all identified problematic entries
data = s[header_index+1:tail_index-1] %>% filter(str_count("\\d+") != 1)
(str_count(s, "\\d+") == 1)
# Remove all identified problematic entries
data = s[header_index+1:tail_index-1] %>% filter((str_count("\\d+")) != 1)
data
# Remove all identified problematic entries
data = s[header_index:tail_index]
data
# Remove all identified problematic entries
data = s[header_index+1:tail_index]
data
# Remove all identified problematic entries
data = s[header_index+1:tail_index+1]
data
# Remove all identified problematic entries
data = s[header_index+1:tail_index]
data
# Remove all identified problematic entries
data = s[header_index+1:tail_index-1]
data
# Remove all identified problematic entries
data = s[header_index+1:tail_index-2]
data
data = data[-9]
data
data = data[-6]
data
# Remove all identified problematic entries
data = s[header_index+1:tail_index-1]
data = data[-9]
data = data[-6]
data
# Find rows w/ only one entry
(str_count(s, "\\d+") == 1) # 2
# Remove all identified problematic entries
data = s[header_index:tail_index]
data
# Remove all identified problematic entries
data = s[header_index+1:tail_index]
data
# Remove all identified problematic entries
data = s[(header_index+1):tail_index]
data
# Remove all identified problematic entries
data = s[(header_index + 1):(tail_index - 1)] %>% s[-7]
# Remove all identified problematic entries
data = s[(header_index + 1):(tail_index - 1)] %>% filter()
class(s)
data = data[-7]
data
data = data[-4]
data
# Remove all identified problematic entries
data = s[(header_index + 1):(tail_index - 1)]
data = data[-7]
data = data[-4]
data
# Remove all identified problematic entries
s = s[(header_index + 1):(tail_index - 1)]
s = s[-7]
s = s[-4]
s
# Remove anything that isn't a num or a space
s = str_remove_all(s, "[^\\d\\s]") # ^ w/in [] means NOT.
s
# Convert s to a data matrix
s = str_split_fixed(s, "\\s+", n = 6)[,1:5]
s
# Give col names
class(s)
?colnames
colnames(s, c("Day", header))
colnames(s) = c("Day", header)
s
# Convert vals to numeric
t = as.numeric(s)
t
# Convert vals to numeric
s
# Convert vals to numeric
t = sapply(s, as.numeric)
t
s
# Convert vals to numeric
data.frame(s)
# Convert vals to numeric
tab = data.frame(s)
tab
tab %>% summarize(deaths_per_day_2015 = X2015/nrow())
tab %>% summarize(deaths_per_day_2015 = X2015/nrow(s))
tab %>% summarize(deaths_per_day_2015 = mean(X2015))
class(tab)
class(tab[1])
class(tab[1][1])
tab %>% mean(X2015)
# Convert vals to numeric
tab = parse_number(s)
tab
# Convert vals to numeric
tab = s %>% parse_number()
tab
s
# Convert vals to numeric
tab = s %>% mutate_at(parse_number(`2015`))
s
# Convert vals to numeric
tab = s %>% data.frame(stringsAsFactors = FALSE) %>%
mutate_at(parse_number)
# Convert vals to numeric
tab = s %>% data.frame(stringsAsFactors = FALSE) %>%
mutate_at(,parse_number)
# Convert vals to numeric
tab = s %>% data.frame(stringsAsFactors = FALSE) %>%
mutate_at(header, parse_number)
# Convert vals to numeric
tab = s %>% data.frame(stringsAsFactors = FALSE) %>%
mutate_at("Day", parse_number)
tab
# Convert vals to numeric
tab = s %>% data.frame(stringsAsFactors = FALSE) %>%
mutate_at(c("Day", "X2015", "X2016", "X2017", "X2018"), parse_number)
tab
mean(tab$X2015)
mean(tab$X2016)
mean(tab$X2017[1:19])
mean(tab$X2017[20:30])
# Plot deaths v day
tab %>% ggplot(aes(Day, -Day, color = -Day)) +
geom_point()
# Plot deaths v day
tab %>% ggplot(aes(Day, c(X2015, X2016, X2017), color = c(X2015, X2016, X2017))) +
geom_point()
tab
names(tab)
# Change tab to tidy format
tab = tab %>% gather(year, deaths, -day) %>%
mutate(deaths = as.numeric(deaths))
# Change tab to tidy format
tab = tab %>% gather(year, deaths, -Day) %>%
mutate(deaths = as.numeric(deaths))
tab
# Plot deaths v day
tab %>% ggplot(aes(Day, deaths, color = year) +
# Plot deaths v day
tab %>% ggplot(aes(Day, deaths, color = year)) +
geom_point()
# Plot deaths v day
tab %>% ggplot(aes(Day, deaths, color = year)) +
geom_point()
tab
# Plot deaths v day
tab(,90) %>% ggplot(aes(Day, deaths, color = year)) +
geom_point()
# Plot deaths v day
tab[,90] %>% ggplot(aes(Day, deaths, color = year)) +
geom_point()
# Plot deaths v day
tab %>% filter(year != "X2018") %>%
ggplot(aes(Day, deaths, color = year)) +
geom_point()
# Plot deaths v day
tab %>% filter(year != "X2018") %>%
ggplot(aes(Day, deaths, color = year, xintercept = 20)) +
geom_point() +
geom_line() +
geom_vline()
# Plot deaths v day
tab %>% filter(year != "X2018") %>%
ggplot(aes(Day, deaths, color = year)) +
geom_point() +
geom_line() +
geom_vline(xintercept = 20)
